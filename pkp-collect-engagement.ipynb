{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PKP crawler\n",
    "\n",
    "Collect altmetric data for PKP publications\n",
    "\n",
    "1. Collect FB shares from Altmetric.com via DOI\n",
    "2. Collect FB shares from FB directly via URLs\n",
    "    - Resolved DOI\n",
    "    - Original PKP URL\n",
    "    - (opt) PMID\n",
    "    - (opt) PMCID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0e8cc66e1c4a6a9d20b46e01f444e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "import sys\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import urllib\n",
    "from dateutil.parser import parse\n",
    "from random import shuffle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lxml.etree as ET\n",
    "from pathlib import Path\n",
    "import configparser\n",
    "from ATB.ATB.Facebook import Facebook\n",
    "from ATB.ATB.Altmetric import Altmetric\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm_notebook().pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated access token: 287299458433880|6Y_ml710QWnU7HBYLWjaneoWVKU\n"
     ]
    }
   ],
   "source": [
    "# Load config\n",
    "Config = configparser.ConfigParser()\n",
    "Config.read('config.cnf')\n",
    "FACEBOOK_APP_ID = Config.get('facebook', 'app_id')\n",
    "FACEBOOK_APP_SECRET = Config.get('facebook', 'app_secret')\n",
    "ALTMETRIC_KEY = Config.get('altmetric', 'key')\n",
    "\n",
    "fb_graph = Facebook(app_id=FACEBOOK_APP_ID, app_secret=FACEBOOK_APP_SECRET)\n",
    "altmetric = Altmetric(api_key = ALTMETRIC_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"output_files/test/\")\n",
    "input_file = Path(\"input_files/PKP_20171220.csv\")\n",
    "url_types = ['pkp', 'doi', 'pmc', 'pmid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions\n",
    "def load_dataset(ids_file, resolv_dois_file):\n",
    "    ncbi = pd.read_csv(ids_file, parse_dates=['ncbi_ts'], index_col=\"doi\")\n",
    "    resolved_dois = pd.read_csv(resolv_dois_file, parse_dates=['doi_resolve_ts'], index_col=\"doi\")\n",
    "    \n",
    "    df = ncbi.merge(resolved_dois[['doi_url']], left_index=True, right_index=True, how=\"inner\")\n",
    "    return df.drop_duplicates()\n",
    "\n",
    "# Facebook\n",
    "def fb_query(url):\n",
    "    og_object = None\n",
    "    og_engagement = None\n",
    "    og_error = None\n",
    "    \n",
    "    try:\n",
    "        fb_response = fb_graph.get_object(\n",
    "            id=urllib.parse.quote_plus(url),\n",
    "            fields=\"engagement, og_object\"\n",
    "        )\n",
    "        \n",
    "        if 'og_object' in fb_response:\n",
    "            og_object = fb_response['og_object']\n",
    "        if 'engagement' in fb_response:\n",
    "            og_engagement = fb_response['engagement']\n",
    "    except Exception as e:\n",
    "        og_error = e\n",
    "  \n",
    "    return (og_object, og_engagement, og_error)\n",
    "\n",
    "def collect_fb_engagement(df):\n",
    "    out_df = df.copy()\n",
    "    for col in  ['og_obj', 'og_eng', 'og_err', 'ts']:\n",
    "        out_df[col] = None\n",
    "    \n",
    "    rows = list(df.itertuples())\n",
    "    for row in tqdm_notebook(rows, total=len(rows)):\n",
    "        now = datetime.datetime.now()\n",
    "        og_object, og_engagement, og_error = fb_query(row.url)\n",
    "        \n",
    "        if og_object:\n",
    "            out_df.loc[(out_df.doi==row.doi) & (out_df.type==row.type), 'og_obj'] = json.dumps(og_object)\n",
    "        if og_engagement:\n",
    "            out_df.loc[(out_df.doi==row.doi) & (out_df.type==row.type), 'og_eng'] = json.dumps(og_engagement)\n",
    "        if og_error:\n",
    "            out_df.loc[(out_df.doi==row.doi) & (out_df.type==row.type), 'og_err'] = str(og_error)\n",
    "        out_df.loc[(out_df.doi==row.doi) & (out_df.type==row.type), 'ts'] = str(now)\n",
    "        \n",
    "    return out_df\n",
    "        \n",
    "# Altmetric\n",
    "def collect_am_engagement(df):\n",
    "    result_cols = ['am_resp', 'am_err', 'ts']\n",
    "    out_df = pd.DataFrame(columns=result_cols, index=df.index)\n",
    "    \n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    rows = list(df.itertuples())\n",
    "    for row in tqdm_notebook(rows, total=len(rows)):\n",
    "        try:\n",
    "            am_resp = altmetric.doi(doi=row.Index, fetch=True)\n",
    "            am_err = None\n",
    "        except Exception as e:\n",
    "            am_resp = None\n",
    "            am_err = e\n",
    "\n",
    "        out_df.loc[row.Index, 'am_resp'] = json.dumps(am_resp)\n",
    "        out_df.loc[row.Index, 'am_err'] = str(am_err)\n",
    "        out_df.loc[row.Index, 'ts'] = str(now)\n",
    "        \n",
    "    return out_df\n",
    "\n",
    "def extract_fb_shares(df):\n",
    "    result_cols = url_types + [x + \"_ogid\" for x in url_types]\n",
    "    shares = pd.DataFrame(columns=result_cols, index=df.doi.unique())\n",
    "    shares.index.name = \"doi\"\n",
    "    \n",
    "    rows = list(df[df.og_obj.notnull()].itertuples())\n",
    "    for row in tqdm_notebook(rows, total=len(rows)):\n",
    "        shares.loc[row.doi, row.type.split(\"_\")[0] + \"_ogid\"] = str(json.loads(row.og_obj)['id'])\n",
    "        shares.loc[row.doi, row.type.split(\"_\")[0]] = float(json.loads(row.og_eng)['share_count'])\n",
    "        \n",
    "    return shares\n",
    "\n",
    "def extract_am_shares(df):\n",
    "    result_cols = ['am', 'am_id']\n",
    "    shares = pd.DataFrame(columns=result_cols, index=df.index.unique())\n",
    "    \n",
    "    rows = list(df[df.am_resp.notnull()].itertuples())\n",
    "    for row in tqdm_notebook(rows, total=len(rows)):\n",
    "        if pd.notnull(row.am_resp):\n",
    "            try:\n",
    "                shares.loc[row.Index, \"am_id\"] = str(json.loads(row.am_resp)['altmetric_id'])\n",
    "            except:\n",
    "                shares.loc[row.Index, \"am_id\"] = None\n",
    "            try:\n",
    "                shares.loc[row.Index, \"am\"] =  float(json.loads(row.am_resp)['counts']['facebook']['posts_count'])\n",
    "            except:\n",
    "                shares.loc[row.Index, \"am\"] = 0.0\n",
    "        #if pd.notnull(row.og_eng):\n",
    "        #    shares.loc[row.doi, row.type.split(\"_\")[0]] =  int(json.loads(row.og_eng)['share_count'])\n",
    "        \n",
    "    return shares\n",
    "\n",
    "def remove_duplicate_og_ids(df):\n",
    "    \"\"\"\n",
    "    Some URLs have been assigned to the same Facebook OG IDs\n",
    "    Those share numbers should be investigated in more detail\n",
    "    but for now they are simply being overwritten with NaNs\n",
    "    \"\"\"\n",
    "    \n",
    "    ids = [x + \"_ogid\" for x in url_types]\n",
    "\n",
    "    for _ in ids:\n",
    "        bad_ones = df[(~df[_].isnull() & df.duplicated(subset=[_], keep=False))].index\n",
    "        df.loc[bad_ones, _.split(\"_\")[0]] = np.nan\n",
    "        print(\"Duplicate {} IDs: {}\".format(_, len(bad_ones)))\n",
    "    return df\n",
    "\n",
    "def get_identical_doi_pkp_urls(df):\n",
    "    \"\"\"\n",
    "    Sum of the individual FB shares (doi, pkp, pmc, pmid) but taking\n",
    "    into account that some URLs are identical for resolved DOI and\n",
    "    original PKP ones.\n",
    "\n",
    "    DOI == PKP: sum(pkp, pmc, pmid)\n",
    "    DOI != PKP: sum(pkp, doi, pmc, pmid)\n",
    "    \"\"\"\n",
    "    x = df[df.type.isin(['pkp_url', 'doi_url'])][['url', 'doi']].copy()\n",
    "    x['netloc'] = x.url.apply(lambda x: urllib.parse.urlparse(x).netloc)\n",
    "    x['path'] = x.url.apply(lambda x: urllib.parse.urlparse(x).path)\n",
    "    return x[x[['netloc', 'path']].duplicated()].doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_with_urls = pd.read_csv(data_folder / \"articles_with_urls.csv\", index_col=\"doi\")\n",
    "\n",
    "df_urls = article_with_urls.reset_index().melt(\n",
    "    value_vars=['pmc_url', 'pmid_url', 'pkp_url', 'doi_url'],\n",
    "    id_vars='doi',\n",
    "    value_name=\"url\",\n",
    "    var_name=\"type\")\n",
    "\n",
    "df_urls = df_urls.replace([\"None\", \"null\", \"\"], np.nan).dropna()\n",
    "df_urls = df_urls.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter out invalid records\n",
    "\n",
    "- Different DOIs with identical PKP URLs\n",
    "- DOIs resolved to the same URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 rows with bad pkp_url\n",
      "Removed 0 rows with bad doi_url\n",
      "Removed 0 rows with bad pmc_url\n",
      "Removed 0 rows with bad pmid_url\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "doi_url    47\n",
       "pkp_url    47\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for _ in [x + \"_url\" for x in url_types]:\n",
    "    selection = df_urls.copy()\n",
    "    selection = selection[selection.type == _]\n",
    "    selection['netloc'] = selection.url.apply(lambda x: urllib.parse.urlparse(x).netloc)\n",
    "    selection['path'] = selection.url.apply(lambda x: urllib.parse.urlparse(x).path)\n",
    "    bad_ones = selection[selection[['netloc', 'path']].duplicated(keep=False)].index\n",
    "    df_urls = df_urls.drop(bad_ones)\n",
    "    print(\"Removed {} rows with bad {}\".format(len(bad_ones), _))\n",
    "    \n",
    "# Sanity check: duplicate URLs need to appear in both PKP and DOI\n",
    "df_urls[df_urls.url.isin(df_urls[df_urls.url.duplicated()].url)].type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect FB engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6460a9af91d432f9328791bb95ff70b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=178), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fb_results = collect_fb_engagement(df_urls)\n",
    "fb_results.to_csv(data_folder / \"fb_responses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect Altmetric engagement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27d62f70c0ef40a8beaac4ee4b801b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "am_results = collect_am_engagement(article_with_urls)\n",
    "am_results = am_results.replace(\"null\", np.nan)\n",
    "am_results.to_csv(data_folder / \"am_responses.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02f8763f9b54e5e81cbfe73a9541467",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e0d6b62aa344dfe97cf3484194eed8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fb_extracted = extract_fb_shares(fb_results)\n",
    "am_extracted = extract_am_shares(am_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate pkp_ogid IDs: 0\n",
      "Duplicate doi_ogid IDs: 0\n",
      "Duplicate pmc_ogid IDs: 0\n",
      "Duplicate pmid_ogid IDs: 0\n"
     ]
    }
   ],
   "source": [
    "fb_extracted = remove_duplicate_og_ids(fb_extracted)\n",
    "doi_pkp_identical = get_identical_doi_pkp_urls(fb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_shares = fb_extracted[url_types].astype(float)\n",
    "am_shares = am_extracted[['am']].astype(float)\n",
    "\n",
    "fb_shares['fb'] = fb_shares[url_types].sum(axis=1)\n",
    "fb_shares.loc[doi_pkp_identical, 'fb'] = fb_shares.loc[doi_pkp_identical, ['pkp', 'pmc', 'pmid']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "fb_shares.to_csv(data_folder / \"fb_shares.csv\")\n",
    "am_shares.to_csv(data_folder / \"am_shares.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "altmetrics",
   "language": "python",
   "name": "altmetrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
